{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tc38Mrhdgm2O"
      },
      "source": [
        "# Deep Neural Networks - Programming Assignment\n",
        "## Comparing Linear Models and Multi-Layer Perceptrons\n",
        "\n",
        "**Student Name:** ___________________  \n",
        "**Student ID:** ___________________  \n",
        "**Date:** ___________________\n",
        "\n",
        "---\n",
        "\n",
        "## ⚠️ IMPORTANT INSTRUCTIONS\n",
        "\n",
        "1. **Complete ALL sections** marked with `TODO`\n",
        "2. **DO NOT modify** the `get_assignment_results()` function structure\n",
        "3. **Fill in all values accurately** - these will be auto-verified\n",
        "4. **After submission**, you'll receive a verification quiz based on YOUR results\n",
        "5. **Run all cells** before submitting (Kernel → Restart & Run All)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oK_4Tm5xgm2S",
        "outputId": "3ca89e9a-02b8-4437-fe19-ede0ffd4fabb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Libraries imported successfully\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "print('✓ Libraries imported successfully')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPXbkEn5gm2V"
      },
      "source": [
        "## Section 1: Dataset Selection and Loading\n",
        "\n",
        "**Requirements:**\n",
        "- ≥500 samples\n",
        "- ≥5 features\n",
        "- Public dataset (UCI/Kaggle)\n",
        "- Regression OR Classification problem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJhf8e1Kgm2V",
        "outputId": "c6276cfe-e164-4a15-9a2d-0a12ddfb94f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset: Wine Quality Dataset (Red Wine)\n",
            "Source: UCI Machine Learning Repository\n",
            "Samples: 1143, Features: 12\n",
            "Problem Type: multiclass_classification\n",
            "Primary Metric: accuracy\n"
          ]
        }
      ],
      "source": [
        "# Load dataset\n",
        "data = pd.read_csv('WineQT.csv')\n",
        "\n",
        "# Dataset information\n",
        "dataset_name = \"Wine Quality Dataset (Red Wine)\"\n",
        "dataset_source = \"UCI Machine Learning Repository\"\n",
        "n_samples = data.shape[0]\n",
        "n_features = data.shape[1] - 1   # excluding 'quality' target\n",
        "problem_type = \"multiclass_classification\"\n",
        "\n",
        "# Problem statement\n",
        "problem_statement = \"\"\"\n",
        "The task is to predict wine quality based on various physicochemical\n",
        "properties such as acidity, sugar, sulfur dioxide levels, and pH.\n",
        "Accurate quality prediction helps in quality control, production monitoring,\n",
        "and maintaining consistency in the wine-making process.\n",
        "\"\"\"\n",
        "\n",
        "# Primary evaluation metric\n",
        "primary_metric = \"accuracy\"\n",
        "\n",
        "# Metric justification\n",
        "metric_justification = \"\"\"\n",
        "Accuracy is selected as the primary metric because this is a balanced\n",
        "multiclass classification problem, and we want to measure how often the\n",
        "model correctly predicts the wine quality class.\n",
        "Additionally, accuracy is easy to interpret and appropriate when\n",
        "misclassification costs across classes are similar.\n",
        "\"\"\"\n",
        "\n",
        "print(f\"Dataset: {dataset_name}\")\n",
        "print(f\"Source: {dataset_source}\")\n",
        "print(f\"Samples: {n_samples}, Features: {n_features}\")\n",
        "print(f\"Problem Type: {problem_type}\")\n",
        "print(f\"Primary Metric: {primary_metric}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FB8DkM4Ygm2W"
      },
      "source": [
        "## Section 2: Data Preprocessing\n",
        "\n",
        "Preprocess your data:\n",
        "1. Handle missing values\n",
        "2. Encode categorical variables\n",
        "3. Split into train/test sets\n",
        "4. Scale features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PoU_XGO8gm2X",
        "outputId": "05958502-6530-43b0-e531-9d3ae4349d46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train samples: 914\n",
            "Test samples: 229\n",
            "Split ratio: 80.0%\n"
          ]
        }
      ],
      "source": [
        "# TODO: Preprocess your data\n",
        "# 1. Separate features (X) and target (y)\n",
        "# 2. Handle missing values if any\n",
        "# 3. Encode categorical variables\n",
        "\n",
        "# 1. Separate features (X) and target (y)\n",
        "X = data.drop('quality', axis=1)\n",
        "y = data['quality']\n",
        "\n",
        "# 2. Handle missing values (WineQT has no missing values, but we ensure safety)\n",
        "X = X.fillna(X.mean())\n",
        "\n",
        "# 3. Encode target variable if needed\n",
        "# Here, quality is already numerical but treated as multiclass labels.\n",
        "\n",
        "# Train-test split (80-20)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Fill reporting variables\n",
        "train_samples = X_train.shape[0]\n",
        "test_samples = X_test.shape[0]\n",
        "train_test_ratio = train_samples / (train_samples + test_samples)\n",
        "\n",
        "print(f\"Train samples: {train_samples}\")\n",
        "print(f\"Test samples: {test_samples}\")\n",
        "print(f\"Split ratio: {train_test_ratio:.1%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tIumCb8gm2X"
      },
      "source": [
        "## Section 3: Baseline Model Implementation\n",
        "\n",
        "Implement from scratch (NO sklearn models!):\n",
        "- Linear Regression (for regression)\n",
        "- Logistic Regression (for binary classification)\n",
        "- Softmax Regression (for multiclass classification)\n",
        "\n",
        "**Must include:**\n",
        "- Forward pass (prediction)\n",
        "- Loss computation\n",
        "- Gradient computation\n",
        "- Gradient descent loop\n",
        "- Loss tracking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4JP45axgm2Y",
        "outputId": "c47f84ba-db97-459f-fcb5-39211662ae26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ BaselineModel (Softmax Regression) ready\n"
          ]
        }
      ],
      "source": [
        "class BaselineModel:\n",
        "    \"\"\"\n",
        "    Baseline linear model with gradient descent\n",
        "    Softmax Regression (multiclass)\n",
        "    \"\"\"\n",
        "    def __init__(self, learning_rate=0.01, n_iterations=1000):\n",
        "        self.lr = learning_rate\n",
        "        self.n_iterations = n_iterations\n",
        "        self.weights = None    # shape: (n_features, n_classes)\n",
        "        self.bias = None       # shape: (1, n_classes)\n",
        "        self.loss_history = []\n",
        "        self.classes_ = None   # original class labels (e.g., [3,4,5,6,7,8])\n",
        "\n",
        "    def _softmax(self, z):\n",
        "        z = z - np.max(z, axis=1, keepdims=True)\n",
        "        exp_z = np.exp(z)\n",
        "        return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
        "\n",
        "    def _cross_entropy(self, probs, y_onehot):\n",
        "        eps = 1e-12\n",
        "        probs = np.clip(probs, eps, 1.0 - eps)\n",
        "        return -np.mean(np.sum(y_onehot * np.log(probs), axis=1))\n",
        "\n",
        "    def _to_onehot(self, y):\n",
        "        \"\"\"\n",
        "        Accepts y as 1D label array (possibly not 0..K-1).\n",
        "        Creates mapping to 0..K-1 and returns one-hot.\n",
        "        \"\"\"\n",
        "        y = np.asarray(y)\n",
        "        if y.ndim == 2 and y.shape[1] > 1:\n",
        "            # Already one-hot\n",
        "            return y\n",
        "        unique = np.unique(y)\n",
        "        self.classes_ = unique\n",
        "        mapping = {v: i for i, v in enumerate(unique)}\n",
        "        y_idx = np.vectorize(mapping.get)(y)\n",
        "        n_classes = unique.shape[0]\n",
        "        oh = np.zeros((y.shape[0], n_classes))\n",
        "        oh[np.arange(y.shape[0]), y_idx] = 1\n",
        "        return oh\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        X: (n_samples, n_features)\n",
        "        y: either (n_samples,) labels or (n_samples, n_classes) one-hot\n",
        "        \"\"\"\n",
        "        X = np.asarray(X)\n",
        "        n_samples, n_features = X.shape\n",
        "\n",
        "        # Convert labels to one-hot; set classes_ for mapping back\n",
        "        y = np.asarray(y)\n",
        "        if y.ndim == 1 or (y.ndim == 2 and y.shape[1] == 1):\n",
        "            y_onehot = self._to_onehot(y)\n",
        "        else:\n",
        "            # assume already one-hot; set classes_ to 0..K-1\n",
        "            y_onehot = y\n",
        "            self.classes_ = np.arange(y.shape[1])\n",
        "\n",
        "        n_classes = y_onehot.shape[1]\n",
        "\n",
        "        # Initialize parameters\n",
        "        # weights shape: (n_features, n_classes)\n",
        "        self.weights = np.zeros((n_features, n_classes))\n",
        "        # bias shape: (1, n_classes)\n",
        "        self.bias = np.zeros((1, n_classes))\n",
        "\n",
        "        # Gradient descent\n",
        "        for it in range(self.n_iterations):\n",
        "            # Forward: logits and probs\n",
        "            logits = X.dot(self.weights) + self.bias  # (n_samples, n_classes)\n",
        "            probs = self._softmax(logits)            # (n_samples, n_classes)\n",
        "\n",
        "            # Loss\n",
        "            loss = self._cross_entropy(probs, y_onehot)\n",
        "            self.loss_history.append(loss)\n",
        "\n",
        "            # Gradients (vectorized)\n",
        "            # derivative of loss w.r.t logits = (probs - y_onehot) / n_samples\n",
        "            dlogits = (probs - y_onehot) / n_samples  # (n_samples, n_classes)\n",
        "            # dW = X^T dot dlogits\n",
        "            dW = X.T.dot(dlogits)                     # (n_features, n_classes)\n",
        "            db = np.sum(dlogits, axis=0, keepdims=True)  # (1, n_classes)\n",
        "\n",
        "            # Parameter update\n",
        "            self.weights -= self.lr * dW\n",
        "            self.bias -= self.lr * db\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        X = np.asarray(X)\n",
        "        logits = X.dot(self.weights) + self.bias\n",
        "        return self._softmax(logits)\n",
        "\n",
        "    def predict(self, X):\n",
        "        probs = self.predict_proba(X)\n",
        "        idx = np.argmax(probs, axis=1)\n",
        "        # Map indices back to original class labels (if available)\n",
        "        if self.classes_ is not None:\n",
        "            return np.array([self.classes_[i] for i in idx])\n",
        "        else:\n",
        "            return idx\n",
        "\n",
        "print(\"✓ BaselineModel (Softmax Regression) ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfVeP5iPgm2Z",
        "outputId": "dba13762-fda3-4c55-9d70-2a31bd18a9ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training baseline model...\n",
            "✓ Baseline training completed in 0.00s\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "list index out of range",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_40180/3751896206.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mbaseline_training_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbaseline_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"✓ Baseline training completed in {baseline_training_time:.2f}s\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"✓ Loss decreased from {baseline_model.loss_history[0]:.4f} to {baseline_model.loss_history[-1]:.4f}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "# Train baseline model\n",
        "print(\"Training baseline model...\")\n",
        "baseline_start_time = time.time()\n",
        "\n",
        "# TODO: Initialize and train your baseline model\n",
        "baseline_model = BaselineModel(learning_rate=0.01, n_iterations=1000)\n",
        "# baseline_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# TODO: Make predictions\n",
        "# baseline_predictions = baseline_model.predict(X_test_scaled)\n",
        "\n",
        "baseline_training_time = time.time() - baseline_start_time\n",
        "print(f\"✓ Baseline training completed in {baseline_training_time:.2f}s\")\n",
        "print(f\"✓ Loss decreased from {baseline_model.loss_history[0]:.4f} to {baseline_model.loss_history[-1]:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yrp-hFYgm2Z"
      },
      "source": [
        "## Section 4: Multi-Layer Perceptron Implementation\n",
        "\n",
        "Implement MLP from scratch with:\n",
        "- At least 1 hidden layer\n",
        "- ReLU activation for hidden layers\n",
        "- Appropriate output activation\n",
        "- Forward propagation\n",
        "- Backward propagation\n",
        "- Gradient descent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUxPV2MUgm2a",
        "outputId": "0ba33d33-0abb-4771-aa06-afbdc42875f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ MLP class ready \n"
          ]
        }
      ],
      "source": [
        "class MLP:\n",
        "    \"\"\"\n",
        "    Multi-Layer Perceptron implemented from scratch (vectorized).\n",
        "    - architecture: [n_input, n_hidden1, ..., n_output]\n",
        "    - Uses ReLU for hidden layers and Softmax for output (multiclass).\n",
        "    - Expects X shape (m, n_input). Labels y can be 1D integer labels or one-hot (m, n_classes).\n",
        "    \"\"\"\n",
        "    def __init__(self, architecture, learning_rate=0.01, n_iterations=1000):\n",
        "        self.architecture = architecture\n",
        "        self.lr = learning_rate\n",
        "        self.n_iterations = n_iterations\n",
        "        self.parameters = {}\n",
        "        self.loss_history = []\n",
        "        self.cache = {}\n",
        "        self.classes_ = None\n",
        "\n",
        "    def _to_onehot(self, y):\n",
        "        y = np.asarray(y)\n",
        "        if y.ndim == 2 and y.shape[1] > 1:\n",
        "            # already one-hot\n",
        "            self.classes_ = np.arange(y.shape[1])\n",
        "            return y\n",
        "        unique = np.unique(y)\n",
        "        self.classes_ = unique\n",
        "        mapping = {v: i for i, v in enumerate(unique)}\n",
        "        y_idx = np.vectorize(mapping.get)(y)\n",
        "        n_classes = unique.shape[0]\n",
        "        oh = np.zeros((y.shape[0], n_classes))\n",
        "        oh[np.arange(y.shape[0]), y_idx] = 1\n",
        "        return oh\n",
        "\n",
        "    def initialize_parameters(self):\n",
        "        \"\"\"\n",
        "        Initialize parameters:\n",
        "         - W[l] shape: (n_prev, n_curr)\n",
        "         - b[l] shape: (1, n_curr)\n",
        "        \"\"\"\n",
        "        np.random.seed(42)\n",
        "        for l in range(1, len(self.architecture)):\n",
        "            n_prev = self.architecture[l-1]\n",
        "            n_curr = self.architecture[l]\n",
        "            # He initialization for hidden layers (works well with ReLU)\n",
        "            self.parameters[f'W{l}'] = np.random.randn(n_prev, n_curr) * np.sqrt(2.0 / max(1, n_prev))\n",
        "            self.parameters[f'b{l}'] = np.zeros((1, n_curr))\n",
        "\n",
        "    def relu(self, Z):\n",
        "        return np.maximum(0, Z)\n",
        "\n",
        "    def relu_derivative(self, Z):\n",
        "        return (Z > 0).astype(float)\n",
        "\n",
        "    def _softmax(self, Z):\n",
        "        Z_stable = Z - np.max(Z, axis=1, keepdims=True)\n",
        "        e = np.exp(Z_stable)\n",
        "        return e / np.sum(e, axis=1, keepdims=True)\n",
        "\n",
        "    def forward_propagation(self, X):\n",
        "        \"\"\"\n",
        "        Forward pass.\n",
        "        Stores:\n",
        "          - cache['A0'] = X\n",
        "          - cache['Zl'], cache['Al'] for each layer l\n",
        "        Returns final activation A_last (probabilities).\n",
        "        \"\"\"\n",
        "        A = X\n",
        "        self.cache = {'A0': A}\n",
        "        L = len(self.architecture) - 1\n",
        "        for l in range(1, L + 1):\n",
        "            W = self.parameters[f'W{l}']   # shape (n_prev, n_curr)\n",
        "            b = self.parameters[f'b{l}']   # shape (1, n_curr)\n",
        "            Z = A.dot(W) + b               # (m, n_curr)\n",
        "            self.cache[f'Z{l}'] = Z\n",
        "            if l < L:\n",
        "                A = self.relu(Z)\n",
        "            else:\n",
        "                A = self._softmax(Z)\n",
        "            self.cache[f'A{l}'] = A\n",
        "        return A\n",
        "\n",
        "    def backward_propagation(self, X, y_onehot):\n",
        "        \"\"\"\n",
        "        Backward pass. y_onehot shape: (m, n_classes)\n",
        "        Returns grads dict with dWl and dbl for each layer.\n",
        "        \"\"\"\n",
        "        m = X.shape[0]\n",
        "        grads = {}\n",
        "        L = len(self.architecture) - 1\n",
        "\n",
        "        # Output layer gradient\n",
        "        A_L = self.cache[f'A{L}']                # (m, n_classes)\n",
        "        dZ = (A_L - y_onehot) / m                # (m, n_classes)\n",
        "\n",
        "        for l in reversed(range(1, L + 1)):\n",
        "            A_prev = self.cache[f'A{l-1}']       # (m, n_prev)\n",
        "            dW = A_prev.T.dot(dZ)                # (n_prev, n_curr)\n",
        "            db = np.sum(dZ, axis=0, keepdims=True)  # (1, n_curr)\n",
        "            grads[f'dW{l}'] = dW\n",
        "            grads[f'db{l}'] = db\n",
        "\n",
        "            if l > 1:\n",
        "                W = self.parameters[f'W{l}']    # (n_prev, n_curr)\n",
        "                dA_prev = dZ.dot(W.T)          # (m, n_prev)\n",
        "                Z_prev = self.cache[f'Z{l-1}'] # (m, n_prev)\n",
        "                dZ = dA_prev * self.relu_derivative(Z_prev)\n",
        "\n",
        "        return grads\n",
        "\n",
        "    def update_parameters(self, grads):\n",
        "        L = len(self.architecture) - 1\n",
        "        for l in range(1, L + 1):\n",
        "            self.parameters[f'W{l}'] -= self.lr * grads[f'dW{l}']\n",
        "            self.parameters[f'b{l}'] -= self.lr * grads[f'db{l}']\n",
        "\n",
        "    def compute_loss(self, y_pred, y_true_onehot):\n",
        "        # Cross-entropy loss (mean)\n",
        "        eps = 1e-12\n",
        "        y_pred = np.clip(y_pred, eps, 1.0 - eps)\n",
        "        return -np.mean(np.sum(y_true_onehot * np.log(y_pred), axis=1))\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        Train the MLP.\n",
        "        Accepts y as 1D labels or as one-hot.\n",
        "        \"\"\"\n",
        "        X = np.asarray(X)\n",
        "        y = np.asarray(y)\n",
        "        y_onehot = self._to_onehot(y)\n",
        "        self.initialize_parameters()\n",
        "\n",
        "        for it in range(self.n_iterations):\n",
        "            # Forward\n",
        "            probs = self.forward_propagation(X)            # (m, n_classes)\n",
        "            # Loss\n",
        "            loss = self.compute_loss(probs, y_onehot)\n",
        "            self.loss_history.append(loss)\n",
        "            # Backward\n",
        "            grads = self.backward_propagation(X, y_onehot)\n",
        "            # Update\n",
        "            self.update_parameters(grads)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        X = np.asarray(X)\n",
        "        probs = self.forward_propagation(X)\n",
        "        return probs\n",
        "\n",
        "    def predict(self, X):\n",
        "        probs = self.predict_proba(X)\n",
        "        idx = np.argmax(probs, axis=1)\n",
        "        if self.classes_ is not None:\n",
        "            return np.array([self.classes_[i] for i in idx])\n",
        "        else:\n",
        "            return idx\n",
        "\n",
        "print(\"✓ MLP class ready \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xaW0EkEJgm2b",
        "outputId": "c9a45c3f-2292-46ca-ad84-41335573a320"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training MLP...\n",
            "✓ MLP training completed in 0.00s\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "list index out of range",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_40180/771147772.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mmlp_training_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmlp_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"✓ MLP training completed in {mlp_training_time:.2f}s\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"✓ Loss decreased from {mlp_model.loss_history[0]:.4f} to {mlp_model.loss_history[-1]:.4f}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "# Train MLP\n",
        "print(\"Training MLP...\")\n",
        "mlp_start_time = time.time()\n",
        "\n",
        "# TODO: Define your architecture and train MLP\n",
        "mlp_architecture = []  # Example: [n_features, 16, 8, 1]\n",
        "mlp_model = MLP(architecture=mlp_architecture, learning_rate=0.01, n_iterations=1000)\n",
        "# mlp_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# TODO: Make predictions\n",
        "# mlp_predictions = mlp_model.predict(X_test_scaled)\n",
        "\n",
        "mlp_training_time = time.time() - mlp_start_time\n",
        "print(f\"✓ MLP training completed in {mlp_training_time:.2f}s\")\n",
        "print(f\"✓ Loss decreased from {mlp_model.loss_history[0]:.4f} to {mlp_model.loss_history[-1]:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mA_thTKqgm2b"
      },
      "source": [
        "## Section 5: Evaluation and Metrics\n",
        "\n",
        "Calculate appropriate metrics for your problem type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eR83gY9tgm2c",
        "outputId": "0e616289-7b24-431c-de47-44bcade424dc"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'baseline_predictions' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_40180/760725349.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;31m# Calculate metrics for baseline & MLP models\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m \u001b[0mbaseline_metrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalculate_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbaseline_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproblem_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m \u001b[0mmlp_metrics\u001b[0m      \u001b[1;33m=\u001b[0m \u001b[0mcalculate_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmlp_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproblem_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'baseline_predictions' is not defined"
          ]
        }
      ],
      "source": [
        "def calculate_metrics(y_true, y_pred, problem_type):\n",
        "    \"\"\"\n",
        "    Calculate metrics for multiclass classification:\n",
        "    - Accuracy\n",
        "    - Precision (macro)\n",
        "    - Recall (macro)\n",
        "    - F1-score (macro)\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "\n",
        "    metrics = {}\n",
        "\n",
        "    # Convert to numpy\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    if problem_type == \"multiclass_classification\":\n",
        "\n",
        "        # Unique class labels\n",
        "        labels = np.unique(np.concatenate([y_true, y_pred]))\n",
        "        n_classes = len(labels)\n",
        "        label_to_idx = {lab: i for i, lab in enumerate(labels)}\n",
        "\n",
        "        # Confusion matrix\n",
        "        cm = np.zeros((n_classes, n_classes), dtype=int)\n",
        "        for t, p in zip(y_true, y_pred):\n",
        "            cm[label_to_idx[t], label_to_idx[p]] += 1\n",
        "\n",
        "        # Per-class stats\n",
        "        tp = np.diag(cm).astype(float)\n",
        "        actual_counts = np.sum(cm, axis=1).astype(float)   # support\n",
        "        pred_counts = np.sum(cm, axis=0).astype(float)     # predicted\n",
        "\n",
        "        # Precision = TP / predicted\n",
        "        precision = np.divide(tp, pred_counts,\n",
        "                              out=np.zeros_like(tp),\n",
        "                              where=pred_counts != 0)\n",
        "\n",
        "        # Recall = TP / actual\n",
        "        recall = np.divide(tp, actual_counts,\n",
        "                           out=np.zeros_like(tp),\n",
        "                           where=actual_counts != 0)\n",
        "\n",
        "        # F1-score\n",
        "        f1 = np.divide(2 * precision * recall,\n",
        "                       precision + recall,\n",
        "                       out=np.zeros_like(tp),\n",
        "                       where=(precision + recall) != 0)\n",
        "\n",
        "        # Macro averaging\n",
        "        precision_macro = float(np.mean(precision))\n",
        "        recall_macro = float(np.mean(recall))\n",
        "        f1_macro = float(np.mean(f1))\n",
        "\n",
        "        # Overall accuracy\n",
        "        accuracy = float(np.trace(cm) / np.sum(cm))\n",
        "\n",
        "        # Save metrics\n",
        "        metrics[\"accuracy\"] = accuracy\n",
        "        metrics[\"precision_macro\"] = precision_macro\n",
        "        metrics[\"recall_macro\"] = recall_macro\n",
        "        metrics[\"f1_macro\"] = f1_macro\n",
        "        metrics[\"confusion_matrix\"] = cm\n",
        "        metrics[\"labels\"] = labels\n",
        "\n",
        "    return metrics\n",
        "\n",
        "\n",
        "# Calculate metrics for baseline & MLP models\n",
        "baseline_metrics = calculate_metrics(y_test, baseline_predictions, problem_type)\n",
        "mlp_metrics      = calculate_metrics(y_test, mlp_predictions, problem_type)\n",
        "\n",
        "print(\"Baseline Model Performance:\")\n",
        "print(baseline_metrics)\n",
        "\n",
        "print(\"\\nMLP Model Performance:\")\n",
        "print(mlp_metrics)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeHt2vuGgm2c"
      },
      "source": [
        "## Section 6: Visualization\n",
        "\n",
        "Create visualizations:\n",
        "1. Training loss curves\n",
        "2. Performance comparison\n",
        "3. Additional domain-specific plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jOZHSgNJgm2d",
        "outputId": "0bd07051-701e-498c-a79b-83c7597aea81"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No handles with labels found to put in legend.\n",
            "No handles with labels found to put in legend.\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 1. Training loss curves\n",
        "plt.figure(figsize=(14, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "# TODO: Plot baseline loss\n",
        "# plt.plot(baseline_model.loss_history, label='Baseline', color='blue')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Baseline Model - Training Loss')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "# TODO: Plot MLP loss\n",
        "# plt.plot(mlp_model.loss_history, label='MLP', color='red')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('MLP Model - Training Loss')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "br3POY5Ygm2e",
        "outputId": "57fb4942-9900-4a77-b207-61598f7d4fda"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Figure size 720x432 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 2. Performance comparison bar chart\n",
        "# TODO: Create bar chart comparing key metrics between models\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Example:\n",
        "# metrics = ['Accuracy', 'Precision', 'Recall', 'F1']\n",
        "# baseline_scores = [baseline_metrics[m] for m in metrics]\n",
        "# mlp_scores = [mlp_metrics[m] for m in metrics]\n",
        "#\n",
        "# x = np.arange(len(metrics))\n",
        "# width = 0.35\n",
        "#\n",
        "# plt.bar(x - width/2, baseline_scores, width, label='Baseline')\n",
        "# plt.bar(x + width/2, mlp_scores, width, label='MLP')\n",
        "# plt.xlabel('Metrics')\n",
        "# plt.ylabel('Score')\n",
        "# plt.title('Model Performance Comparison')\n",
        "# plt.xticks(x, metrics)\n",
        "# plt.legend()\n",
        "# plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qg3P8vLfgm2e"
      },
      "source": [
        "## Section 7: Analysis and Discussion\n",
        "\n",
        "Write your analysis (minimum 200 words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBokBi_Ugm2f"
      },
      "outputs": [],
      "source": [
        "analysis_text = \"\"\"\n",
        "TODO: Write your analysis here (minimum 200 words)\n",
        "\n",
        "Address these questions:\n",
        "1. Which model performed better and by how much?\n",
        "2. Why do you think one model outperformed the other?\n",
        "3. What was the computational cost difference (training time)?\n",
        "4. Any surprising findings or challenges you faced?\n",
        "5. What insights did you gain about neural networks vs linear models?\n",
        "\n",
        "Write your thoughtful analysis here. Be specific and reference your actual results.\n",
        "Compare the metrics, discuss the trade-offs, and explain what you learned.\n",
        "\"\"\"\n",
        "\n",
        "print(f\"Analysis word count: {len(analysis_text.split())} words\")\n",
        "if len(analysis_text.split()) < 200:\n",
        "    print(\"⚠️  Warning: Analysis should be at least 200 words\")\n",
        "else:\n",
        "    print(\"✓ Analysis meets word count requirement\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbKfL6QLgm2f"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "## ⭐ REQUIRED: Structured Output Function\n",
        "\n",
        "### **DO NOT MODIFY THE STRUCTURE BELOW**\n",
        "\n",
        "This function will be called by the auto-grader. Fill in all values accurately based on your actual results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rr7Wdustgm2f"
      },
      "outputs": [],
      "source": [
        "def get_assignment_results():\n",
        "    \"\"\"\n",
        "    Return all assignment results in structured format.\n",
        "\n",
        "    CRITICAL: Fill in ALL values based on your actual results!\n",
        "    This will be automatically extracted and validated.\n",
        "    \"\"\"\n",
        "\n",
        "    # Calculate loss convergence flags\n",
        "    baseline_initial_loss = 0.0  # TODO: baseline_model.loss_history[0]\n",
        "    baseline_final_loss = 0.0    # TODO: baseline_model.loss_history[-1]\n",
        "    mlp_initial_loss = 0.0       # TODO: mlp_model.loss_history[0]\n",
        "    mlp_final_loss = 0.0         # TODO: mlp_model.loss_history[-1]\n",
        "\n",
        "    results = {\n",
        "        # ===== Dataset Information =====\n",
        "        'dataset_name': dataset_name,\n",
        "        'dataset_source': dataset_source,\n",
        "        'n_samples': n_samples,\n",
        "        'n_features': n_features,\n",
        "        'problem_type': problem_type,\n",
        "        'problem_statement': problem_statement,\n",
        "\n",
        "        # ===== Evaluation Setup =====\n",
        "        'primary_metric': primary_metric,\n",
        "        'metric_justification': metric_justification,\n",
        "        'train_samples': train_samples,\n",
        "        'test_samples': test_samples,\n",
        "        'train_test_ratio': train_test_ratio,\n",
        "\n",
        "        # ===== Baseline Model Results =====\n",
        "        'baseline_model': {\n",
        "            'model_type': '',  # 'linear_regression', 'logistic_regression', or 'softmax_regression'\n",
        "            'learning_rate': 0.0,\n",
        "            'n_iterations': 0,\n",
        "            'initial_loss': baseline_initial_loss,\n",
        "            'final_loss': baseline_final_loss,\n",
        "            'training_time_seconds': baseline_training_time,\n",
        "\n",
        "            # Metrics (fill based on your problem type)\n",
        "            'test_accuracy': 0.0,      # For classification\n",
        "            'test_precision': 0.0,     # For classification\n",
        "            'test_recall': 0.0,        # For classification\n",
        "            'test_f1': 0.0,            # For classification\n",
        "            'test_mse': 0.0,           # For regression\n",
        "            'test_rmse': 0.0,          # For regression\n",
        "            'test_mae': 0.0,           # For regression\n",
        "            'test_r2': 0.0,            # For regression\n",
        "        },\n",
        "\n",
        "        # ===== MLP Model Results =====\n",
        "        'mlp_model': {\n",
        "            'architecture': mlp_architecture,\n",
        "            'n_hidden_layers': len(mlp_architecture) - 2 if len(mlp_architecture) > 0 else 0,\n",
        "            'total_parameters': 0,     # TODO: Calculate total weights + biases\n",
        "            'learning_rate': 0.0,\n",
        "            'n_iterations': 0,\n",
        "            'initial_loss': mlp_initial_loss,\n",
        "            'final_loss': mlp_final_loss,\n",
        "            'training_time_seconds': mlp_training_time,\n",
        "\n",
        "            # Metrics\n",
        "            'test_accuracy': 0.0,\n",
        "            'test_precision': 0.0,\n",
        "            'test_recall': 0.0,\n",
        "            'test_f1': 0.0,\n",
        "            'test_mse': 0.0,\n",
        "            'test_rmse': 0.0,\n",
        "            'test_mae': 0.0,\n",
        "            'test_r2': 0.0,\n",
        "        },\n",
        "\n",
        "        # ===== Comparison =====\n",
        "        'improvement': 0.0,            # MLP primary_metric - baseline primary_metric\n",
        "        'improvement_percentage': 0.0,  # (improvement / baseline) * 100\n",
        "        'baseline_better': False,       # True if baseline outperformed MLP\n",
        "\n",
        "        # ===== Analysis =====\n",
        "        'analysis': analysis_text,\n",
        "        'analysis_word_count': len(analysis_text.split()),\n",
        "\n",
        "        # ===== Loss Convergence Flags =====\n",
        "        'baseline_loss_decreased': baseline_final_loss < baseline_initial_loss,\n",
        "        'mlp_loss_decreased': mlp_final_loss < mlp_initial_loss,\n",
        "        'baseline_converged': False,  # Optional: True if converged\n",
        "        'mlp_converged': False,\n",
        "    }\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UolS9nwAgm2g"
      },
      "source": [
        "## Test Your Output\n",
        "\n",
        "Run this cell to verify your results dictionary is complete and properly formatted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xIxLs6kygm2g"
      },
      "outputs": [],
      "source": [
        "# Test the output\n",
        "import json\n",
        "\n",
        "try:\n",
        "    results = get_assignment_results()\n",
        "\n",
        "    print(\"=\"*70)\n",
        "    print(\"ASSIGNMENT RESULTS SUMMARY\")\n",
        "    print(\"=\"*70)\n",
        "    print(json.dumps(results, indent=2, default=str))\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "\n",
        "    # Check for missing values\n",
        "    missing = []\n",
        "    def check_dict(d, prefix=\"\"):\n",
        "        for k, v in d.items():\n",
        "            if isinstance(v, dict):\n",
        "                check_dict(v, f\"{prefix}{k}.\")\n",
        "            elif (v == 0 or v == \"\" or v == 0.0 or v == []) and \\\n",
        "                 k not in ['improvement', 'improvement_percentage', 'baseline_better',\n",
        "                          'baseline_converged', 'mlp_converged', 'total_parameters',\n",
        "                          'test_accuracy', 'test_precision', 'test_recall', 'test_f1',\n",
        "                          'test_mse', 'test_rmse', 'test_mae', 'test_r2']:\n",
        "                missing.append(f\"{prefix}{k}\")\n",
        "\n",
        "    check_dict(results)\n",
        "\n",
        "    if missing:\n",
        "        print(f\"⚠️  Warning: {len(missing)} fields still need to be filled:\")\n",
        "        for m in missing[:15]:  # Show first 15\n",
        "            print(f\"  - {m}\")\n",
        "        if len(missing) > 15:\n",
        "            print(f\"  ... and {len(missing)-15} more\")\n",
        "    else:\n",
        "        print(\"✅ All required fields are filled!\")\n",
        "        print(\"\\n🎉 You're ready to submit!\")\n",
        "        print(\"\\nNext steps:\")\n",
        "        print(\"1. Kernel → Restart & Clear Output\")\n",
        "        print(\"2. Kernel → Restart & Run All\")\n",
        "        print(\"3. Verify no errors\")\n",
        "        print(\"4. Save notebook\")\n",
        "        print(\"5. Rename as: YourStudentID_assignment.ipynb\")\n",
        "        print(\"6. Submit to LMS\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error in get_assignment_results(): {str(e)}\")\n",
        "    print(\"\\nPlease fix the errors above before submitting.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0erPQ_Wgm2h"
      },
      "source": [
        "---\n",
        "\n",
        "## 📤 Before Submitting - Final Checklist\n",
        "\n",
        "- [ ] **All TODO sections completed**\n",
        "- [ ] **Both models implemented from scratch** (no sklearn models!)\n",
        "- [ ] **get_assignment_results() function filled accurately**\n",
        "- [ ] **Loss decreases for both models**\n",
        "- [ ] **Analysis ≥ 200 words**\n",
        "- [ ] **All cells run without errors** (Restart & Run All)\n",
        "- [ ] **Visualizations created**\n",
        "- [ ] **File renamed correctly**: YourStudentID_assignment.ipynb\n",
        "\n",
        "---\n",
        "\n",
        "## ⏭️ What Happens Next\n",
        "\n",
        "After submission:\n",
        "1. ✅ Your notebook will be **auto-graded** (executes automatically)\n",
        "2. ✅ You'll receive a **verification quiz** (10 questions, 5 minutes)\n",
        "3. ✅ Quiz questions based on **YOUR specific results**\n",
        "4. ✅ Final score released after quiz validation\n",
        "\n",
        "**The verification quiz ensures you actually ran your code!**\n",
        "\n",
        "---\n",
        "\n",
        "**Good luck! 🚀**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}